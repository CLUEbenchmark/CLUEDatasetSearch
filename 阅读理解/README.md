

| ID   | 标题                                                         | 更新日期   | 数据集提供者                | 许可                   | 说明                                                         | 关键字                     | 类别                          | 论文地址                                                     | 备注                                                         |
| ---- | ------------------------------------------------------------ | ---------- | --------------------------- | ---------------------- | ------------------------------------------------------------ | -------------------------- | ----------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1    | [百度WebQA](https://spaces.ac.cn/archives/4338) | 2016   | 百度                        | \              | <font size=2> 来自于百度知道；格式为一个问题多篇意思基本一致的文章，分为人为标注以及浏览器检索</font> | 阅读理解、百度知道真实问题 | 中文阅读理解                  | [论文](https://arxiv.org/abs/1607.06275)                     |                                                              |
| 2    | [百度DuReader中文阅读理解数据集](http://ai.baidu.com/broad/download?dataset=dureader) | 2018/3/1   | 百度                        | Apache2.0              | <font size=2> 本次竞赛数据集来自搜索引擎真实应用场景，其中的问题为百度搜索用户的真实问题，每个问题对应5个候选文档文本及人工整理的优质答案。 </font> | 阅读理解、百度搜索真实问题 | 中文阅读理解                  | [论文](https://arxiv.org/abs/1711.05073)                     |                                                              |
| 3    | [SogouQA](http://task.www.sogou.com/cips-sogou_qa/) | 2018  | 搜狗                        | \              | <font size=2>CIPS-SOGOU问答比赛数据；来自于搜狗搜索引擎真实用户提交的查询请求；含有事实类与非事实类数据| 阅读理解、搜狗搜索引擎真实问题</font> | 中文阅读理解                  | \                     |                                                              |
| 4    | [中文法律阅读理解数据集CJRC](https://github.com/china-ai-law-challenge/CAIL2019) | 2019/8/17  | 哈工大讯飞联合实验室（HFL） | \                      | <font size=2> 数据集包含约10,000篇文档，主要涉及民事一审判决书和刑事一审判决书。通过抽取裁判文书的事实描述内容，针对事实描述内容标注问题，最终形成约50,000个问答对 </font> | 阅读理解、中文法律领域     | 中文阅读理解                  | [论文](https://link.springer.com/chapter/10.1007/978-3-030-32381-3_36) |                                                              |
| 5    | [2019“讯飞杯”中文机器阅读理解数据集（CMRC ）](https://github.com/ymcui/cmrc2019) | 2019年10月 | 哈工大讯飞联合实验室（HFL） | CC-BY-SA-4.0           | <font size=2> 本次阅读理解的任务是句子级填空型阅读理解。 根据给定的一个叙事篇章以及若干个从篇章中抽取出的句子，参赛者需要建立模型将候选句子精准的填回原篇章中，使之成为完整的一篇文章。 </font> | 句子级填空型阅读理解       | 中文阅读理解                  | \                                                            | 赛事官网：https://hfl-rc.github.io/cmrc2019/                 |
| 6    | [2018“讯飞杯”中文机器阅读理解数据集（CMRC ）](https://github.com/ymcui/cmrc2018) | 2018/10/19 | 哈工大讯飞联合实验室（HFL） | CC-BY-SA-4.0           | <font size=2> CMRC 2018数据集包含了约20,000个在维基百科文本上人工标注的问题。同时，我们还标注了一个挑战集，其中包含了需要多句推理才能够正确解答的问题，更富有挑战性 </font> | 阅读理解、基于篇章片段抽取 | 中文阅读理解                  | [论文](https://www.aclweb.org/anthology/D19-1600/)           | 赛事官网：https://hfl-rc.github.io/cmrc2018/                 |
| 7    | [2017“讯飞杯”中文机器阅读理解数据集（CMRC ）](https://github.com/ymcui/Chinese-Cloze-RC) | 2017/10/14 | 哈工大讯飞联合实验室（HFL） | CC-BY-SA-4.0           | <font size=2> 首个中文填空型阅读理解数据集PD&CFT                           </font> | 填空型阅读理解             | 中文阅读理解                  | [论文](https://arxiv.org/abs/1607.02250)                     | [赛事官网](https://hfl-rc.github.io/cmrc2017/)               |
| 8    | [莱斯杯：全国第二届“军事智能机器阅读”挑战赛](https://www.kesci.com/home/competition/5d142d8cbb14e6002c04e14a/content/5) | 2019/9/3   | 中电莱斯信息系统有限公司    | \                      | <font size=2> 面向军事应用场景的大规模中文阅读理解数据集，围绕多文档机器阅读理解进行竞赛，涉及理解、推理等复杂技术。 </font> | 多文档机器阅读理解         | 中文阅读理解                  | \                                                            | [赛事官网](https://www.kesci.com/home/competition/5d142d8cbb14e6002c04e14a) |
| 9    | [ReCO](https://github.com/benywon/ReCO) | 2020   | 搜狗    | \                      | <font size=2> 来源于搜狗的浏览器用户输入；有多选和直接答案 </font> | 阅读理解、搜狗搜索         | 中文阅读理解                  | [论文](https://arxiv.org/abs/2006.12146)                                                            | \ |
| 10    | [DuReader-checklist](https://github.com/baidu/DuReader) | 2021/3   | 百度    | Apache-2.0                       | <font size=2> 建立了细粒度的、多维度的评测数据集，从词汇理解、短语理解、语义角色理解、逻辑推理等多个维度检测模型的不足之处，从而推动阅读理解评测进入“精细化“时代 </font> | 细粒度阅读理解         | 中文阅读理解                  | \                                                            | [赛事官网](https://aistudio.baidu.com/aistudio/competition/detail/66) |
| 11    | [DuReader-Robust](https://github.com/baidu/DuReader) | 2020/8   | 百度    | Apache-2.0                       | <font size=2> 从过敏感性，过稳定性以及泛化性多个维度构建了测试阅读理解鲁棒性的数据 </font> | 百度搜索、鲁棒性阅读理解         | 中文阅读理解                  | [论文](https://arxiv.org/abs/2004.11142)                                                            | [赛事官网](https://aistudio.baidu.com/aistudio/competition/detail/49/0/task-definition) |
| 12    | [DuReader-YesNo](https://github.com/baidu/DuReader) | 2020/8   | 百度    | Apache-2.0                       | <font size=2> DuReader yesno是一个以观点极性判断为目标任务的数据集，可以弥补抽取类数据集评测指标的缺陷，从而更好地评价模型对观点极性的理解能力。 </font> | 观点型阅读理解         | 中文阅读理解                  | \                                                            | [赛事官网](https://aistudio.baidu.com/aistudio/competition/detail/49/0/task-definition) |
| 13    | [DuReader2.0](https://github.com/baidu/DuReader) | 2021   | 百度    | Apache-2.0                       | <font size=2> DuReader2.0是全新的大规模中文阅读理解数据，来源于用户真实输入，真实场景</font> | 阅读理解         | 中文阅读理解                  | [论文](https://www.aclweb.org/anthology/W18-2605.pdf)                                                            | [赛事官网](https://ai.baidu.com/broad/leaderboard?dataset=dureader) |
| 14   | [CAIL2020](http://cail.cipsc.org.cn:2020/) | 2020   |   哈工大讯飞联合实验室（HFL）  |\                     | <font size=2> 中文司法阅读理解任务，今年我们将提出升级版，不仅文书种类由民事、刑事扩展为民事、刑事、行政，问题类型也由单步预测扩展为多步推理，难度有所升级。</font> | 法律阅读理解         | 中文阅读理解                  |\                                                             | [赛事官网](http://cail.cipsc.org.cn:2020/) |
| 15    | [CAIL2021](http://cail.cipsc.org.cn/index.html) | 2021   |   哈工大讯飞联合实验室（HFL）  |\                     | <font size=2> 中文法律阅读理解比赛引入多片段回答的问题类型，即部分问题需要抽取文章中的多个片段组合成最终答案。希望多片段问题类型的引入，能够扩大中文机器阅读理解的场景适用性。本次比赛依旧保留单片段、是否类和拒答类的问题类型。</font> | 法律阅读理解         | 中文阅读理解                  |\                                                             | [赛事官网](http://cail.cipsc.org.cn/task1.html?raceID=0) |
| 16   | [CoQA](https://stanfordnlp.github.io/coqa/)                  | 2018/9     | 斯坦福大学                  | CC BY-SA 4.0、Apache等 | <font size=2> CoQA是面向建立对话式问答系统的大型数据集，挑战的目标是衡量机器对文本的理解能力，以及机器面向对话中出现的彼此相关的问题的回答能力的高低 </font> | 对话问答                   | 英文阅读理解                  | [论文](https://arxiv.org/abs/1808.07042)                     | [官方网站](https://www.jiqizhixin.com/articles/2018-09-11-3) |
| 17    | [SQuAD2.0](https://github.com/rajpurkar/SQuAD-explorer/tree/master/dataset) | 2018/1/11  | 斯坦福大学                  | \                      | <font size=2> 行业内公认的机器阅读理解领域的顶级水平测试；它构建了一个包含十万个问题的大规模机器阅读理解数据集，选取超过 500 篇的维基百科文章。数据集中每一个阅读理解问题的答案是来自给定的阅读文章的一小段文本 —— 以及，现在在 SQuAD 2.0 中还要判断这个问题是否能够根据当前的阅读文本作答 </font> | 问答、包含未知答案         | 英文阅读理解                  | [论文](https://arxiv.org/abs/1806.03822)                     |                                                              |
| 18   | [SQuAD1.0](https://github.com/rajpurkar/SQuAD-explorer/tree/master/dataset) | 2016       | 斯坦福大学                  | \                      | <font size=2> 斯坦福大学于2016年推出的阅读理解数据集，给定一篇文章和相应问题，需要算法给出问题的答案。此数据集所有文章选自维基百科，一共有107,785问题，以及配套的 536 篇文章 </font> | 问答、基于篇章片段抽取     | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1606.05250.pdf)                 |                                                              |
| 19   | [MCTest](https://www.microsoft.com/en-us/research/publication/mctest-challenge-dataset-open-domain-machine-comprehension-text/) | 2013       | 微软                        | \                      | <font size=2> 100,000个必应Bing问题和人工生成的答案。从那时起，相继发布了1,000,000个问题数据集，自然语言生成数据集，段落排名数据集，关键词提取数据集，爬网数据集和会话搜索。 </font> | 问答、搜索                 | 英文阅读理解                  | [论文](https://microsoft.github.io/msmarco/)                 |                                                              |
| 20   | [CNN/Dailymail](https://cs.nyu.edu/~kcho/DMQA/)              | 2015       | DeepMind                    | Apache-2.0             | <font size=2> 填空型大规模英文机器理解数据集，答案是原文中的某一个词。 CNN数据集包含美国有线电视新闻网的新闻文章和相关问题。大约有90k文章和380k问题。 Dailymail数据集包含每日新闻的文章和相关问题。大约有197k文章和879k问题。 </font> | 问答对、填空型阅读理解     | 英文阅读理解                  | [论文](https://arxiv.org/abs/1506.03340)                     |                                                              |
| 21   | [RACE](http://www.cs.cmu.edu/~glai1/data/race/)              | 2017       | 卡耐基梅隆大学              | /                      | <font size=2> 数据集为中国中学生英语阅读理解题目，给定一篇文章和 5 道 4 选 1 的题目，包括了 28000+ passages 和 100,000 问题。 </font> | 选择题形式                 | 英文阅读理解                  | [论文](https://arxiv.org/abs/1704.04683)                     | 下载需邮件申请                                               |
| 22   | [HEAD-QA](https://github.com/aghie/head-qa)                  | 2019       | aghie                       | MIT                    | <font size=2> 一个面向复杂推理的医疗保健、多选问答数据集。提供英语、西班牙语两种形式的数据 </font> | 医疗领域、选择题形式       | 英文阅读理解 西班牙语阅读理解 | [论文](https://arxiv.org/pdf/1906.04701.pdf)                 |                                                              |
| 23   | [Consensus Attention-based Neural Networks for Chinese Reading Comprehension](http://hfl.iflytek.com/chinese-rc/) | 2018       | 哈工大讯飞联合实验室        | /                      | <font size=2> 中文完形填空型阅读理解                                       </font> | 填空型阅读理解             | 中文阅读理解                  | [论文](https://arxiv.org/pdf/1607.02250.pdf)                 |                                                              |
| 24   | [WikiQA](https://www.microsoft.com/en-us/research/publication/wikiqa-a-challenge-dataset-for-open-domain-question-answering/) | 2015       | 微软                        | /                      | <font size=2> WikiQA语料库是一个新的公开的问题和句子对集，收集并注释用于开放域问答研究 </font> | 片段抽取阅读理解           | 英文阅读理解                  | [论文](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf) |                                                              |
| 25   | [Children’s Book Test (CBT)](https://research.fb.com/downloads/babi/) | 2016       | Facebook                    | /                      | <font size=2> 测试语言模型如何在儿童书籍中捕捉意义。与标准语言建模基准不同，它将预测句法功能词的任务与预测语义内容更丰富的低频词的任务区分开来 </font> | 填空型阅读理解             | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1511.02301.pdf)                 |                                                              |
| 26   | [NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset/) | 2017       | Maluuba Research            | /                      | <font size=2> 一个具有挑战性的机器理解数据集，包含超过100000个人工生成的问答对，根据CNN的10000多篇新闻文章提供问题和答案，答案由相应文章的文本跨度组成。 </font> | 片段抽取阅读理解           | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1611.09830.pdf)                 |                                                              |
| 27   | [Frames dataset](https://www.microsoft.com/en-us/research/project/frames-dataset/#!download) | 2017       | 微软                        | /                      | 介绍了一个由1369个人类对话组成的框架数据集，平均每个对话15轮。开发这个数据集是为了研究记忆在目标导向对话系统中的作用。 | 阅读理解、对话             | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1704.00057.pdf)                 |                                                              |
| 28   | [Quasar](https://github.com/bdhingra/quasar)                 | 2017       | 卡内基梅隆大学              | BSD-2-Clause           | <font size=2> 提出了两个大规模数据集。Quasar-S数据集由37000个完形填空式查询组成，这些查询是根据流行网站 Stack overflow 上的软件实体标记的定义构造的。网站上的帖子和评论是回答完形填空问题的背景语料库。Quasar-T数据集包含43000个开放域琐事问题及其从各种互联网来源获得的答案。 </font> | 片段抽取阅读理解           | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1707.03904.pdf)                 |                                                              |
| 29   | [MS MARCO](http://www.msmarco.org/dataset.aspx)              | 2018       | 微软                        | /                      | <font size=2> 微软基于搜索引擎 BING 构建的大规模英文阅读理解数据集，包含10万个问题和20万篇不重复的文档。MARCO 数据集中的问题全部来自于 BING 的搜索日志，根据用户在 BING 中输入的真实问题模拟搜索引擎中的真实应用场景，是该领域最有应用价值的数据集之一。 </font> | 多文档                     | 英文阅读理解                  | [论文](https://arxiv.org/pdf/1611.09268.pdf)                 |                                                              |
| 30   | [中文完形填空](https://github.com/ymcui/Chinese-Cloze-RC)    | 2016年     | 崔一鸣                      |                        | <font size=2> 首个中文填空型阅读理解数据集PD&CFT， 全称People Daily and Children's Fairy Tale， 数据来源于人民日报和儿童故事。 </font> | 填空型阅读理解             | 中文完形填空                  | [论文](http://aclanthology.info/papers/consensus-attention-based-neural-networks-for-chinese-reading-comprehension) |                                                              |
| 31   | [NLPCC ICCPOL2016](http://tcci.ccf.org.cn/conference/2016/)  | 2016.12.2  | NLPCC主办方                 |                        | <font size=2> 基于文档中的句子人工合成14659个问题，包括14K中文篇章。       </font> | 问答对阅读理解             | 中文阅读理解                  | \                                                            |                                                              |
